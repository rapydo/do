name: Test

on:
  push:
  pull_request:
  workflow_dispatch:

# Cancel previous running jobs on the same branch in case of new pushs
concurrency:
  group: do-tests-${{ github.ref }}
  cancel-in-progress: true

jobs:
  build:
    runs-on: ubuntu-latest
    timeout-minutes: 20

    strategy:
      matrix:
        test: [
            # > 6 minutes
            backup_restore_mariadb,
            backup_restore_neo4j,
            backup_restore_postgres,
            backup_restore_rabbit,
            backup_restore_redis,
            logs,
            password_neo4j,
            password_rabbit,
            reload,
            shell,
            start,

            # ~ 5-6 minutes
            install,
            multi_host,
            password_backend,
            password_mysql,
            password_postgres,
            password_redis,
            registry,
            remove,
            run,
            scale,

            # ~ 3-4 minutes
            build_pull,
            list,
            cronjobs,
            password_flower,
            restart,
            ssl,
            status,

            # ~ 1-3 minutes
            add_upgrade,
            base,
            check,
            create,
            dump,
            init,
            join,
            libs,
            password,
            password_registry,
            tuning,
            update,
          ]

    steps:
      - uses: actions/checkout@v3
      - name: Select a Python version
        run: |
          versions=(3.8 3.9 3.10)
          PYTHON_VERSION=${versions[$(($RANDOM % ${#versions[@]}))]}
          echo "PYTHON_VERSION=${PYTHON_VERSION}" >> $GITHUB_ENV
        shell: bash
      - name: Set up Python ${{ env.PYTHON_VERSION }}
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      - name: Install
        run: |
          python -m pip install --upgrade pip
          pip install --upgrade --no-cache-dir --editable .[dev]
          # Needed to make git commit (used by tests) to work and prevent error: 'Author identity unknown'
          git config --global user.email "tests@rapy.do"
          git config --global user.name "RAPyDo"

          rapydo install buildx
          rapydo install compose

      - name: Run Compose Tests
        env:
          LOGURU_LEVEL: DEBUG
          TESTING: 1
          TEST_NAME: ${{ matrix.test }}
          PYTHONMALLOC: debug
          PYTHONASYNCIODEBUG: 1
          # Convert warnings to exceptions
          # PYTHONWARNINGS: error
          PYTHONFAULTHANDLER: 1
          COLUMNS: 160
        run: |

          mkdir rapydo_tests
          cd rapydo_tests

          py.test --timeout=600 --durations=5 -s -x --cov-report=xml --cov=.. ../tests/test_${TEST_NAME}.py

      - name: Send Compose Coverage
        uses: rapydo/actions/coverage@v2
        with:
          repository: .
          cov_file: rapydo_tests/coverage.xml

      - name: Clean the environment
        env:
          LOGURU_LEVEL: DEBUG
          TESTING: 1
          TEST_NAME: ${{ matrix.test }}
        run: |
          # Remove containers, networks, volumes and images
          docker rm -f $(docker ps -a -q) || true
          docker volume rm $(docker volume ls -q) || true
          docker network rm $(docker network ls -q) || true
          docker rmi $(docker images -q) || true
          docker system prune -f

          sudo rm -rf rapydo_tests

      - name: Run Swarm Tests
        if: ${{ matrix.test != 'install' }}
        env:
          LOGURU_LEVEL: DEBUG
          TESTING: 1
          SWARM_MODE: 1
          TEST_NAME: ${{ matrix.test }}
          PYTHONMALLOC: debug
          PYTHONASYNCIODEBUG: 1
          # Convert warnings to exceptions
          # PYTHONWARNINGS: error
          PYTHONFAULTHANDLER: 1
          COLUMNS: 160
        run: |
          mkdir rapydo_tests
          cd rapydo_tests

          IP_DEV=$(python3 -c "from controller.utilities import system; print(system.get_local_ip(production=False))")
          IP_PROD=$(python3 -c "from controller.utilities import system; print(system.get_local_ip(production=True))")
          sudo cat /etc/docker/daemon.json
          sudo bash -c "echo '{\"cgroup-parent\": \"/actions_job\", \"insecure-registries\" : [\"${IP_DEV}:5000\", \"${IP_PROD}:5000\"]}' >  /etc/docker/daemon.json"
          sudo cat /etc/docker/daemon.json
          sudo systemctl restart docker.service

          if [[ "${TEST_NAME}" == "multi_host" ]]; then

            docker swarm init
            JOIN_COMMAND=$(docker swarm join-token  worker | tail -2 | head)
            echo "Join command = ${JOIN_COMMAND}"

            # NFS to be added
            export NFS_HOST="127.0.0.1"

            # Create all volumes used by NFS expect for ssl_certs
            sudo mkdir -p /volumes/secrets
            sudo mkdir -p /volumes/rabbitdata
            sudo mkdir -p /volumes/sqldata
            sudo mkdir -p /volumes/mariadb
            sudo mkdir -p /volumes/graphdata
            sudo mkdir -p /volumes/data_imports
            sudo mkdir -p /volumes/redisdata
          fi

          if [[ "${TEST_NAME}" == "multi_host-based-on-docker-machine-NOT-USED" ]]; then

            base=https://github.com/docker/machine/releases/download/v0.16.0 \
              && curl --silent -L $base/docker-machine-$(uname -s)-$(uname -m) >/tmp/docker-machine \
              && sudo mv /tmp/docker-machine /usr/local/bin/docker-machine \
              && chmod +x /usr/local/bin/docker-machine

            docker-machine --version

            sudo apt-get update -qq
            sudo apt-get install --yes virtualbox
            docker swarm init
            JOIN_COMMAND=$(docker swarm  join-token  worker | tail -2 | head)
            echo "Join command = ${JOIN_COMMAND}"

            # Currently not working due to lack of nested virtualization:
            # VBoxManage: error: VT-x is not available (VERR_VMX_NO_VMX)
            # docker-machine create --driver virtualbox --virtualbox-no-vtx-check --swarm test
            # docker-machine ssh test $JOIN_COMMAND
            # docker node ls

            # NFS to be added
            export NFS_HOST="127.0.0.1"

            # Create all volumes used by NFS expect for ssl_certs
            sudo mkdir -p /volumes/secrets
            sudo mkdir -p /volumes/rabbitdata
            sudo mkdir -p /volumes/sqldata
            sudo mkdir -p /volumes/mariadb
            sudo mkdir -p /volumes/graphdata
            sudo mkdir -p /volumes/data_imports
            sudo mkdir -p /volumes/redisdata
          fi

          py.test --timeout=600 --durations=5 -s -x --cov-report=xml --cov=.. ../tests/test_${TEST_NAME}.py
      - name: Send Swarm Coverage
        if: ${{ matrix.test != 'install' }}
        uses: rapydo/actions/coverage@v2
        with:
          repository: .
          cov_file: rapydo_tests/coverage.xml
